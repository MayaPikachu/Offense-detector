{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsdodXP3zRm6HUpR30UVpm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MayaPikachu/Offense-detector/blob/main/Offense_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install unidecode\n",
        "!pip install tokenizers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ec0PCg0fGFdF",
        "outputId": "c990439f-612b-4abd-a571-cb471fd503b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (1.3.8)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBvYYFfRzcRc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "from unidecode import unidecode\n",
        "from tokenizers import ByteLevelBPETokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"SBIC.v2.trn.csv\")\n",
        "dt = pd.read_csv(\"SBIC.v2.tst.csv\")"
      ],
      "metadata": {
        "id": "MeVH-BIfzy74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poststrn = df.post.values\n",
        "resultstrn = df.offensiveYN.values\n",
        "\n",
        "poststst = dt.post.values\n",
        "resultstst = dt.offensiveYN.values\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "tokenizer.train_from_iterator([poststrn[:int(4E7)]], vocab_size=500, min_frequency=5)\n",
        "\n",
        "vocab_size = tokenizer.get_vocab_size()\n",
        "\n",
        "print(f\"\\n\\n\\tTokenizado! Vocab_size = {vocab_size}\\n\")\n",
        "\n",
        "encode = lambda s: tokenizer.encode(s).ids\n",
        "decode = lambda ids: tokenizer.decode(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDcvK7u80Fgq",
        "outputId": "e0a89c95-914f-43af-a2ed-8974b16008a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\tTokenizado! Vocab_size = 500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 20\n",
        "batch_size = 64\n",
        "iter = 3000\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def get_data(file, results, batch_size = batch_size):\n",
        "  X, Y = [], []\n",
        "  for i in range(batch_size):\n",
        "    ix = torch.randint(0, len(file), (1, ))\n",
        "    input = (encode(file[ix]) + [0] * block_size)[:block_size]\n",
        "    X.append(input)\n",
        "    Y.append(results[ix])\n",
        "  return torch.tensor(X).float(), torch.nan_to_num(torch.tensor(Y).float(), nan=0.0)\n",
        "\n",
        "get_data(poststrn, resultstrn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGzEJWlZHLrz",
        "outputId": "956e0720-a401-4378-d4a2-17d822a7b88b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[158., 250., 100.,  ..., 260., 487., 295.],\n",
              "         [ 49.,  51., 383.,  ...,  68., 284.,  72.],\n",
              "         [ 34., 279., 257.,  ..., 316., 363.,  30.],\n",
              "         ...,\n",
              "         [ 35.,  68., 346.,  ..., 295.,  68., 329.],\n",
              "         [ 45., 278.,  76.,  ..., 282., 420., 442.],\n",
              "         [ 39., 305., 485.,  ..., 298., 257., 285.]]),\n",
              " tensor([0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.5000, 0.0000, 1.0000,\n",
              "         1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000,\n",
              "         0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5000, 0.0000, 1.0000, 0.0000,\n",
              "         0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
              "         0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
              "         0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
              "         1.0000]))"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, n_hidden):\n",
        "    super().__init__()\n",
        "    self.l1 = nn.Linear(block_size, n_hidden)\n",
        "    self.l2 = nn.Linear(n_hidden, n_hidden)\n",
        "    self.l3 = nn.Linear(n_hidden, 1)\n",
        "    self.s = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.l1(x))\n",
        "    x = nn.Dropout(0.2)(F.relu(self.l2(x)))\n",
        "    x = nn.Dropout(0.2)(self.l3(x))\n",
        "    return self.s(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "fwRz8T8DNWdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(128)\n",
        "model.to(device)\n",
        "params = list(model.parameters())\n",
        "optimizer = torch.optim.Adam(params, lr=0.0003)\n",
        "loss_fn = nn.BCELoss()\n",
        "for i in range(iter):\n",
        "  X, Y = get_data(poststrn, resultstrn)\n",
        "  X = X.to(device)\n",
        "  Y = Y.to(device)\n",
        "  optimizer.zero_grad()\n",
        "  logits = model(X)\n",
        "  loss = loss_fn(logits, Y.unsqueeze(1))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if (i%100 == 0):\n",
        "    print(f'step = {i}, loss = {loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HWjGb4FZ4-y",
        "outputId": "31fd517b-fb1c-42bb-9365-8eb9d363ab89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 0, loss = 34.46164321899414\n",
            "step = 100, loss = 5.232851505279541\n",
            "step = 200, loss = 1.0635298490524292\n",
            "step = 300, loss = 0.7637502551078796\n",
            "step = 400, loss = 0.8205668330192566\n",
            "step = 500, loss = 0.6767224073410034\n",
            "step = 600, loss = 0.6415577530860901\n",
            "step = 700, loss = 0.7463389039039612\n",
            "step = 800, loss = 0.6746700406074524\n",
            "step = 900, loss = 0.6852728128433228\n",
            "step = 1000, loss = 0.720058262348175\n",
            "step = 1100, loss = 0.6961688995361328\n",
            "step = 1200, loss = 0.6768128871917725\n",
            "step = 1300, loss = 0.6743472814559937\n",
            "step = 1400, loss = 0.6614426374435425\n",
            "step = 1500, loss = 0.6822410821914673\n",
            "step = 1600, loss = 0.6610668301582336\n",
            "step = 1700, loss = 0.685003399848938\n",
            "step = 1800, loss = 0.711157500743866\n",
            "step = 1900, loss = 0.7497321963310242\n",
            "step = 2000, loss = 0.6878183484077454\n",
            "step = 2100, loss = 0.6482507586479187\n",
            "step = 2200, loss = 0.6556747555732727\n",
            "step = 2300, loss = 0.6547324657440186\n",
            "step = 2400, loss = 0.693442702293396\n",
            "step = 2500, loss = 0.6370221972465515\n",
            "step = 2600, loss = 0.6415247321128845\n",
            "step = 2700, loss = 0.702286422252655\n",
            "step = 2800, loss = 0.6346662044525146\n",
            "step = 2900, loss = 0.690269410610199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precisao = 0.0\n",
        "for i in range(30):\n",
        "  X, Y = get_data(poststst, resultstst)\n",
        "  X = X.to(device)\n",
        "  Y = Y.to(device)\n",
        "  logits = model(X)\n",
        "  precisao += (logits.round() == Y.unsqueeze(1)).float().mean()/30.\n",
        "  print(f'x: {decode(X[1].int().to(\"cpu\").tolist())}, y = {Y[1].to(\"cpu\")}, predito = {0 if logits[1].to(\"cpu\").item() < .5 else 1}')\n",
        "\n",
        "print(precisao)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbOLg0ewVNUJ",
        "outputId": "6bdc5981-4569-49e4-c3c7-83c82e2f7862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: Stupid kids of stupid liberals and st, y = 1.0, predito = 1\n",
            "x: Society is like a box of chocolates, y = 1.0, predito = 1\n",
            "x: NYC fiber optic cut on purpose..., y = 0.0, predito = 1\n",
            "x: What’s the problem with replacing your dishw, y = 1.0, predito = 1\n",
            "x: I would like to say and I can proudly say that there, y = 1.0, predito = 1\n",
            "x: You're a girl.  You're not expect, y = 1.0, predito = 1\n",
            "x: If you eat leftover pizza you are ince, y = 1.0, predito = 1\n",
            "x: Run run as fast as you can Run run as fast as you can, y = 0.5, predito = 1\n",
            "x: What do you call a Jewish pokémon train, y = 1.0, predito = 1\n",
            "x: So I failed to get accepted at Harvar, y = 1.0, predito = 0\n",
            "x: I have a hint for you in my usename @et_twe, y = 1.0, predito = 1\n",
            "x: Today, I bought a Rolex from a black gu, y = 1.0, predito = 0\n",
            "x: Women whose third child is born foll, y = 0.0, predito = 1\n",
            "x: Aan indian was taking a dump and died. St, y = 1.0, predito = 1\n",
            "x: what is the difference between a homosexu, y = 1.0, predito = 1\n",
            "x: what do you call a retarded jew ? auschwist, y = 1.0, predito = 1\n",
            "x: A Jewish toddler drowned recently., y = 1.0, predito = 1\n",
            "x: These fat hoes think they slick posting, y = 1.0, predito = 1\n",
            "x: 12-year-old boy is Kerala's youn, y = 0.0, predito = 0\n",
            "x: Wasn't that when Steve and Bean got their head, y = 0.0, predito = 1\n",
            "x: My brother told me that he wanted to kill himse, y = 1.0, predito = 1\n",
            "x: Randy Blazak is an `` expert ', y = 0.5, predito = 1\n",
            "x: i named my son michael simon albert tim, y = 0.0, predito = 1\n",
            "x: \"@jaikpuppyteeth @rubble, y = 0.0, predito = 0\n",
            "x: Spreading a woman's legs is like spreading, y = 1.0, predito = 1\n",
            "x: Why don't Africans play on Minecraf, y = 1.0, predito = 1\n",
            "x: People are like chicken... They taste better dee, y = 0.0, predito = 1\n",
            "x: A black guy and Mexican were in a car, Wh, y = 1.0, predito = 1\n",
            "x: Do gay guys face a much discrim, y = 0.0, predito = 1\n",
            "x: The fuck's up with the bot saying white people can't comment, y = 0.5, predito = 1\n",
            "tensor(0.6198)\n"
          ]
        }
      ]
    }
  ]
}